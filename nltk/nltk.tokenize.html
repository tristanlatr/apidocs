<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize</title>
    <meta name="generator" content="pydoctor 22.2.2.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a> <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        <div>
          <span class="label label-default" id="search-docstrings-button">
            <a title="Search in docstrings" onclick="toggleSearchInDocstrings()">search in docstrings</a></span>
        </div>

        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all objects 
                  in "twisted.mail" that matches “search”: <code>+qname:twisted.mail.* +search</code>

                  <p>
                    Possible fields: 'name', 'qname' (fully qualified name), 'docstring', and 'kind'.
                    Last two fields are only applicable if "search in docstrings" is enabled.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>
        
        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div style="margin-top: 8px;">
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>
  </div>

  <script src="ajax.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="package"><code><code><a href="index.html" class="internal-link">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html" class="internal-link" title="nltk.tokenize">tokenize</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        package documentation
      </div>

      <div class="extrasDocstring">
        <a href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/__init__.py" class="sourceLink">(source)</a>
        <p></p>
      </div>

      <div class="moduleDocstring">
        <div><p>NLTK Tokenizer Package</p>
<p>Tokenizers divide strings into lists of substrings.  For example,
tokenizers can be used to find the words and punctuation in a string:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize <span class="py-keyword">import</span> word_tokenize
<span class="py-prompt">&gt;&gt;&gt; </span>s = <span class="py-string">'''Good muffins cost $3.88\nin New York.  Please buy me</span>
<span class="py-more">... </span><span class="py-string">two of them.\n\nThanks.'''</span>
<span class="py-prompt">&gt;&gt;&gt; </span>word_tokenize(s)
<span class="py-output">['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.',</span>
<span class="py-output">'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']</span>
</pre></blockquote>
<p>This particular tokenizer requires the Punkt sentence tokenization
models to be installed. NLTK also provides a simpler,
regular-expression based tokenizer, which splits text on whitespace
and punctuation:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize <span class="py-keyword">import</span> wordpunct_tokenize
<span class="py-prompt">&gt;&gt;&gt; </span>wordpunct_tokenize(s)
<span class="py-output">['Good', 'muffins', 'cost', '$', '3', '.', '88', 'in', 'New', 'York', '.',</span>
<span class="py-output">'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']</span>
</pre></blockquote>
<p>We can also operate at the level of sentences, using the sentence
tokenizer directly as follows:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize <span class="py-keyword">import</span> sent_tokenize, word_tokenize
<span class="py-prompt">&gt;&gt;&gt; </span>sent_tokenize(s)
<span class="py-output">['Good muffins cost $3.88\nin New York.', 'Please buy me\ntwo of them.', 'Thanks.']</span>
<span class="py-prompt">&gt;&gt;&gt; </span>[word_tokenize(t) <span class="py-keyword">for</span> t <span class="py-keyword">in</span> sent_tokenize(s)]
<span class="py-output">[['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.'],</span>
<span class="py-output">['Please', 'buy', 'me', 'two', 'of', 'them', '.'], ['Thanks', '.']]</span>
</pre></blockquote>
<p>Caution: when tokenizing a Unicode string, make sure you are not
using an encoded version of the string (it may be necessary to
decode it first, e.g. with <tt class="rst-docutils literal"><span class="pre">s.decode("utf8")</span></tt>.</p>
<p>NLTK tokenizers can produce token-spans, represented as tuples of integers
having the same semantics as string slices, to support efficient comparison
of tokenizers.  (These methods are implemented as generators.)</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize <span class="py-keyword">import</span> WhitespaceTokenizer
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-builtin">list</span>(WhitespaceTokenizer().span_tokenize(s))
<span class="py-output">[(0, 4), (5, 12), (13, 17), (18, 23), (24, 26), (27, 30), (31, 36), (38, 44),</span>
<span class="py-output">(45, 48), (49, 51), (52, 55), (56, 58), (59, 64), (66, 73)]</span>
</pre></blockquote>
<p>There are numerous ways to tokenize text.  If you need more control over
tokenization, see the other methods provided in this package.</p>
<p>For further information, please see Chapter 3 of the NLTK book.</p>
</div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1780">
  
  
  <tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.api.html" class="internal-link" title="nltk.tokenize.api">api</a></code></td>
    <td>Tokenizer Interface</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.casual.html" class="internal-link" title="nltk.tokenize.casual">casual</a></code></td>
    <td>Twitter-aware tokenizer, designed to be flexible and easy to adapt to new domains and tasks. The basic logic is this:</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.destructive.html" class="internal-link" title="nltk.tokenize.destructive">destructive</a></code></td>
    <td><span class="undocumented">No module docstring; 2/2 classes documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.legality_principle.html" class="internal-link" title="nltk.tokenize.legality_principle">legality​_principle</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.mwe.html" class="internal-link" title="nltk.tokenize.mwe">mwe</a></code></td>
    <td>Multi-Word Expression Tokenizer</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.nist.html" class="internal-link" title="nltk.tokenize.nist">nist</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.punkt.html" class="internal-link" title="nltk.tokenize.punkt">punkt</a></code></td>
    <td>Punkt Sentence Tokenizer</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.regexp.html" class="internal-link" title="nltk.tokenize.regexp">regexp</a></code></td>
    <td>Regular-Expression Tokenizers</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.repp.html" class="internal-link" title="nltk.tokenize.repp">repp</a></code></td>
    <td><span class="undocumented">No module docstring; 1/1 class documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.sexpr.html" class="internal-link" title="nltk.tokenize.sexpr">sexpr</a></code></td>
    <td>S-Expression Tokenizer</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.simple.html" class="internal-link" title="nltk.tokenize.simple">simple</a></code></td>
    <td>Simple Tokenizers</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.sonority_sequencing.html" class="internal-link" title="nltk.tokenize.sonority_sequencing">sonority​_sequencing</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.stanford.html" class="internal-link" title="nltk.tokenize.stanford">stanford</a></code></td>
    <td><span class="undocumented">No module docstring; 0/1 variable, 1/1 class documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.stanford_segmenter.html" class="internal-link" title="nltk.tokenize.stanford_segmenter">stanford​_segmenter</a></code></td>
    <td><span class="undocumented">No module docstring; 0/1 variable, 1/1 class documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.texttiling.html" class="internal-link" title="nltk.tokenize.texttiling">texttiling</a></code></td>
    <td><span class="undocumented">No module docstring; 0/5 constant, 1/2 function, 3/3 classes documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.toktok.html" class="internal-link" title="nltk.tokenize.toktok">toktok</a></code></td>
    <td>The tok-tok tokenizer is a simple, general tokenizer, where the input has one sentence per line; thus only final period is tokenized.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.treebank.html" class="internal-link" title="nltk.tokenize.treebank">treebank</a></code></td>
    <td>Penn Treebank Tokenizer</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.tokenize.util.html" class="internal-link" title="nltk.tokenize.util">util</a></code></td>
    <td><span class="undocumented">No module docstring; 7/7 functions, 1/1 class documented</span></td>
  </tr>
</table>
        

          <p class="fromInitPy">From <code>__init__.py</code>:</p><table class="children sortable" id="id1781">
  
  
  <tr class="function">
    
    <td>Function</td>
    <td><code><a href="#sent_tokenize" class="internal-link" title="nltk.tokenize.sent_tokenize">sent​_tokenize</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#word_tokenize" class="internal-link" title="nltk.tokenize.word_tokenize">word​_tokenize</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="variable private">
    
    <td>Variable</td>
    <td><code><a href="#_treebank_word_tokenizer" class="internal-link" title="nltk.tokenize._treebank_word_tokenizer">_treebank​_word​_tokenizer</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
      </div>

      <div id="childList">

        <div class="basefunction">
  
  
  <a name="nltk.tokenize.sent_tokenize">
    
  </a>
  <a name="sent_tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sent_tokenize</span>(text, language=<span class="rst-variable-quote">'</span><span class="rst-variable-string">english</span><span class="rst-variable-quote">'</span>):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/__init__.py#L97">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return a sentence-tokenized copy of <em>text</em>,
using NLTK's recommended sentence tokenizer
(currently <code>.PunktSentenceTokenizer</code>
for the specified language).<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">text</span></td><td class="fieldArgDesc">text to split into sentences</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">language</span></td><td class="fieldArgDesc">the model name in the Punkt corpus</td></tr></table></div>
  </div>
</div><div class="basevariable private">
  
  
  <a name="nltk.tokenize._treebank_word_tokenizer">
    
  </a>
  <a name="_treebank_word_tokenizer">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_treebank_word_tokenizer</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/__init__.py#L112">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
    
  </div>
</div><div class="basefunction">
  
  
  <a name="nltk.tokenize.word_tokenize">
    
  </a>
  <a name="word_tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">word_tokenize</span>(text, language=<span class="rst-variable-quote">'</span><span class="rst-variable-string">english</span><span class="rst-variable-quote">'</span>, preserve_line=False):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/__init__.py#L115">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return a tokenized copy of <em>text</em>,
using NLTK's recommended word tokenizer
(currently an improved <code>.TreebankWordTokenizer</code>
along with <code>.PunktSentenceTokenizer</code>
for the specified language).<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">text:</span>str</td><td class="fieldArgDesc">text to split into words</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">language:</span>str</td><td class="fieldArgDesc">the model name in the Punkt corpus</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">preserve​_line:</span>bool</td><td class="fieldArgDesc">An option to keep the preserve the sentence and not sentence tokenize it.</td></tr></table></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.2.dev0 at 2022-03-04 05:57:24.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>