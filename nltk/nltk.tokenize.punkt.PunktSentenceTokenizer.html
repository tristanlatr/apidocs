<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.punkt.PunktSentenceTokenizer</title>
    <meta name="generator" content="pydoctor 22.2.2.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a> <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        <div>
          <span class="label label-default" id="search-docstrings-button">
            <a title="Search in docstrings" onclick="toggleSearchInDocstrings()">search in docstrings</a></span>
        </div>

        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all objects 
                  in "twisted.mail" that matches “search”: <code>+qname:twisted.mail.* +search</code>

                  <p>
                    Possible fields: 'name', 'qname' (fully qualified name), 'docstring', and 'kind'.
                    Last two fields are only applicable if "search in docstrings" is enabled.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>
        
        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div style="margin-top: 8px;">
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>
  </div>

  <script src="ajax.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="index.html" class="internal-link">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html" class="internal-link" title="nltk.tokenize">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.punkt.html" class="internal-link" title="nltk.tokenize.punkt">punkt</a></code><wbr></wbr>.<code><a href="nltk.tokenize.punkt.PunktSentenceTokenizer.html" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer">PunktSentenceTokenizer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">PunktSentenceTokenizer</span>(<a href="nltk.tokenize.punkt.PunktBaseClass.html" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a>, <a href="nltk.tokenize.api.TokenizerI.html" class="internal-link" title="nltk.tokenize.api.TokenizerI">TokenizerI</a>): <a href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1233" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.punkt.PunktSentenceTokenizer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div>A sentence tokenizer which uses an unsupervised algorithm to build
a model for abbreviation words, collocations, and words that start
sentences; and then uses that model to find sentence boundaries.
This approach has been shown to work well for many European
languages.</div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1808">
  
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.__init__">__init__</a></code></td>
    <td>train_text can either be the sole training text for this sentence boundary detector, or can be a PunktParameters object.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#debug_decisions" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.debug_decisions">debug​_decisions</a></code></td>
    <td>Classifies candidate periods as sentence breaks, yielding a dict for each that may be used to understand why the decision was made.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#dump" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.dump">dump</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_text" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text">sentences​_from​_text</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_text_legacy" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text_legacy">sentences​_from​_text​_legacy</a></code></td>
    <td>Given a text, generates the sentences in that text. Annotates all tokens, rather than just those with possible sentence breaks. Should produce the same results as <tt class="rst-docutils literal">sentences_from_text</tt>.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_tokens" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_tokens">sentences​_from​_tokens</a></code></td>
    <td>Given a sequence of tokens, generates lists of tokens, each list corresponding to a sentence.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#span_tokenize" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.span_tokenize">span​_tokenize</a></code></td>
    <td>Given a text, generates (start, end) spans of sentences in the text.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#text_contains_sentbreak" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.text_contains_sentbreak">text​_contains​_sentbreak</a></code></td>
    <td>Returns True if the given text includes a sentence break.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.tokenize">tokenize</a></code></td>
    <td>Given a text, returns a list of the sentences in that text.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.train">train</a></code></td>
    <td>Derives parameters from a given training text, or uses the parameters given. Repeated calls to this method destroy previous parameters. For incremental training, instantiate a separate PunktTrainer instance.</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#PUNCTUATION" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer.PUNCTUATION">PUNCTUATION</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_annotate_second_pass" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_second_pass">_annotate​_second​_pass</a></code></td>
    <td>Performs a token-based classification (section 4) over the given tokens, making use of the orthographic heuristic (4.1.1), collocation heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_annotate_tokens" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_tokens">_annotate​_tokens</a></code></td>
    <td>Given a set of tokens augmented with markers for line-start and paragraph-start, returns an iterator through those tokens with full annotation including predicted sentence breaks.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_build_sentence_list" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._build_sentence_list">_build​_sentence​_list</a></code></td>
    <td>Given the original text and the list of augmented word tokens, construct and return a tokenized list of sentence strings.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_ortho_heuristic" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._ortho_heuristic">_ortho​_heuristic</a></code></td>
    <td>Decide whether the given token is the first token in a sentence.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_realign_boundaries" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._realign_boundaries">_realign​_boundaries</a></code></td>
    <td>Attempts to realign punctuation that falls after the period but should otherwise be included in the same sentence.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_second_pass_annotation" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._second_pass_annotation">_second​_pass​_annotation</a></code></td>
    <td>Performs token-based classification over a pair of contiguous tokens updating the first.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_slices_from_text" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._slices_from_text">_slices​_from​_text</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_params" class="internal-link" title="nltk.tokenize.punkt.PunktSentenceTokenizer._params">_params</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.punkt.PunktBaseClass.html" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a></code>:
          </p>
          <table class="children sortable" id="id1809">
  
  
  <tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_annotate_first_pass" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._annotate_first_pass">_annotate​_first​_pass</a></code></td>
    <td>Perform the first pass of annotation, which makes decisions based purely based on the word type of each word:</td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_first_pass_annotation" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._first_pass_annotation">_first​_pass​_annotation</a></code></td>
    <td>Performs type-based annotation on a single token.</td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_tokenize_words" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._tokenize_words">_tokenize​_words</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_lang_vars" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._lang_vars">_lang​_vars</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_Token" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._Token">_​Token</a></code></td>
    <td>The collection of parameters that determines the behavior of the punkt tokenizer.</td>
  </tr>
</table>
          
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.api.TokenizerI.html" class="internal-link" title="nltk.tokenize.api.TokenizerI">TokenizerI</a></code>:
          </p>
          <table class="children sortable" id="id1810">
  
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize_sents" class="internal-link" title="nltk.tokenize.api.TokenizerI.span_tokenize_sents">span​_tokenize​_sents</a></code></td>
    <td>Apply <tt class="rst-docutils literal">self.span_tokenize()</tt> to each element of <tt class="rst-docutils literal">strings</tt>.  I.e.:</td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#tokenize_sents" class="internal-link" title="nltk.tokenize.api.TokenizerI.tokenize_sents">tokenize​_sents</a></code></td>
    <td>Apply <tt class="rst-docutils literal">self.tokenize()</tt> to each element of <tt class="rst-docutils literal">strings</tt>.  I.e.:</td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, train_text=None, verbose=False, lang_vars=None, token_cls=<a href="nltk.tokenize.punkt.PunktToken.html" class="internal-link" title="nltk.tokenize.punkt.PunktToken">PunktToken</a>):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1242">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#__init__" class="internal-link">nltk.tokenize.punkt.PunktBaseClass.__init__</a></code></div>
    
    <div>train_text can either be the sole training text for this sentence
boundary detector, or can be a PunktParameters object.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.debug_decisions">
    
  </a>
  <a name="debug_decisions">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">debug_decisions</span>(self, text):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1276">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>Classifies candidate periods as sentence breaks, yielding a dict for
each that may be used to understand why the decision was made.</p>
<p>See format_debug_decision() to help make this output readable.</p>
</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.dump">
    
  </a>
  <a name="dump">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">dump</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1487">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text">
    
  </a>
  <a name="sentences_from_text">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_text</span>(self, text, realign_boundaries=True):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1321">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Given a text, generates the sentences in that text by only
testing candidate sentence breaks. If realign_boundaries is
True, includes in the sentence closing punctuation that
follows the period.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text_legacy">
    
  </a>
  <a name="sentences_from_text_legacy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_text_legacy</span>(self, text):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1387">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Given a text, generates the sentences in that text. Annotates all
tokens, rather than just those with possible sentence breaks. Should
produce the same results as <tt class="rst-docutils literal">sentences_from_text</tt>.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_tokens">
    
  </a>
  <a name="sentences_from_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_tokens</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1396">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Given a sequence of tokens, generates lists of tokens, each list
corresponding to a sentence.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.span_tokenize">
    
  </a>
  <a name="span_tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">span_tokenize</span>(self, text, realign_boundaries=True):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1310">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize" class="internal-link">nltk.tokenize.api.TokenizerI.span_tokenize</a></code></div>
    
    <div>Given a text, generates (start, end) spans of sentences
in the text.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.text_contains_sentbreak">
    
  </a>
  <a name="text_contains_sentbreak">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">text_contains_sentbreak</span>(self, text):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1375">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns True if the given text includes a sentence break.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, text, realign_boundaries=True):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1270">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize" class="internal-link">nltk.tokenize.api.TokenizerI.tokenize</a></code></div>
    
    <div>Given a text, returns a list of the sentences in that text.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.train">
    
  </a>
  <a name="train">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train</span>(self, train_text, verbose=False):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1254">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Derives parameters from a given training text, or uses the parameters
given. Repeated calls to this method destroy previous parameters. For
incremental training, instantiate a separate PunktTrainer instance.</div>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.PUNCTUATION">
    
  </a>
  <a name="PUNCTUATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PUNCTUATION</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1504">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>tuple(<wbr></wbr><span class="rst-variable-quote">'</span><span class="rst-variable-string">;:,.!?</span><span class="rst-variable-quote">'</span>)</code></pre></td></tr></table>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_second_pass">
    
  </a>
  <a name="_annotate_second_pass">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_annotate_second_pass</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1510">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Performs a token-based classification (section 4) over the given
tokens, making use of the orthographic heuristic (4.1.1), collocation
heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_tokens">
    
  </a>
  <a name="_annotate_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_annotate_tokens</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1411">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Given a set of tokens augmented with markers for line-start and
paragraph-start, returns an iterator through those tokens with full
annotation including predicted sentence breaks.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._build_sentence_list">
    
  </a>
  <a name="_build_sentence_list">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_build_sentence_list</span>(self, text, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1432">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Given the original text and the list of augmented word tokens,
construct and return a tokenized list of sentence strings.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._ortho_heuristic">
    
  </a>
  <a name="_ortho_heuristic">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_ortho_heuristic</span>(self, aug_tok):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1603">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Decide whether the given token is the first token in a sentence.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._realign_boundaries">
    
  </a>
  <a name="_realign_boundaries">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_realign_boundaries</span>(self, text, slices):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1345">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>Attempts to realign punctuation that falls after the period but
should otherwise be included in the same sentence.</p>
<p>For example: "(Sent1.) Sent2." will otherwise be split as:</p>
<pre class="rst-literal-block">
["(Sent1.", ") Sent1."].
</pre>
<p>This method will produce:</p>
<pre class="rst-literal-block">
["(Sent1.)", "Sent2."].
</pre>
</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._second_pass_annotation">
    
  </a>
  <a name="_second_pass_annotation">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_second_pass_annotation</span>(self, aug_tok1, aug_tok2):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1520">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Performs token-based classification over a pair of contiguous tokens
updating the first.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._slices_from_text">
    
  </a>
  <a name="_slices_from_text">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_slices_from_text</span>(self, text):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1330">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._params">
    
  </a>
  <a name="_params">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_params</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1252">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_params" class="internal-link">nltk.tokenize.punkt.PunktBaseClass._params</a></code></div>
    
    <div><p class="undocumented">Undocumented</p></div>
    
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.2.dev0 at 2022-03-04 05:57:24.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>