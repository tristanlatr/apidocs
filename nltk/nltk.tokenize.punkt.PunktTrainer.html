<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.punkt.PunktTrainer</title>
    <meta name="generator" content="pydoctor 22.2.2.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a> <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        <div>
          <span class="label label-default" id="search-docstrings-button">
            <a title="Search in docstrings" onclick="toggleSearchInDocstrings()">search in docstrings</a></span>
        </div>

        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all objects 
                  in "twisted.mail" that matches “search”: <code>+qname:twisted.mail.* +search</code>

                  <p>
                    Possible fields: 'name', 'qname' (fully qualified name), 'docstring', and 'kind'.
                    Last two fields are only applicable if "search in docstrings" is enabled.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>
        
        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div style="margin-top: 8px;">
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>
  </div>

  <script src="ajax.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="index.html" class="internal-link">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html" class="internal-link" title="nltk.tokenize">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.punkt.html" class="internal-link" title="nltk.tokenize.punkt">punkt</a></code><wbr></wbr>.<code><a href="nltk.tokenize.punkt.PunktTrainer.html" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer">PunktTrainer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">PunktTrainer</span>(<a href="nltk.tokenize.punkt.PunktBaseClass.html" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a>): <a href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L629" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.punkt.PunktTrainer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div>Learns parameters used in Punkt sentence boundary detection.</div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1806">
  
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.__init__">__init__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#finalize_training" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.finalize_training">finalize​_training</a></code></td>
    <td>Uses data that has been gathered in training to determine likely collocations and sentence starters.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#find_abbrev_types" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.find_abbrev_types">find​_abbrev​_types</a></code></td>
    <td>Recalculates abbreviations given type frequencies, despite no prior determination of abbreviations. This fails to include abbreviations otherwise found as "rare".</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#freq_threshold" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.freq_threshold">freq​_threshold</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#get_params" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.get_params">get​_params</a></code></td>
    <td>Calculates and returns parameters for sentence boundary detection as derived from training.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.train">train</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train_tokens" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.train_tokens">train​_tokens</a></code></td>
    <td>Collects training data from a given list of tokens.</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#ABBREV" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.ABBREV">ABBREV</a></code></td>
    <td>cut-off value whether a 'token' is an abbreviation</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#ABBREV_BACKOFF" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.ABBREV_BACKOFF">ABBREV​_BACKOFF</a></code></td>
    <td>upper cut-off for Mikheev's(2002) abbreviation detection algorithm</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#COLLOCATION" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.COLLOCATION">COLLOCATION</a></code></td>
    <td>minimal log-likelihood value that two tokens need to be considered as a collocation</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#IGNORE_ABBREV_PENALTY" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.IGNORE_ABBREV_PENALTY">IGNORE​_ABBREV​_PENALTY</a></code></td>
    <td>allows the disabling of the abbreviation penalty heuristic, which exponentially disadvantages words that are found at times without a final period.</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#INCLUDE_ABBREV_COLLOCS" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ABBREV_COLLOCS">INCLUDE​_ABBREV​_COLLOCS</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#INCLUDE_ALL_COLLOCS" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ALL_COLLOCS">INCLUDE​_ALL​_COLLOCS</a></code></td>
    <td>this includes as potential collocations all word pairs where the first word ends in a period. It may be useful in corpora where there is a lot of variation that makes abbreviations like Mr difficult to identify.</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#MIN_COLLOC_FREQ" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.MIN_COLLOC_FREQ">MIN​_COLLOC​_FREQ</a></code></td>
    <td>this sets a minimum bound on the number of times a bigram needs to appear before it can be considered a collocation, in addition to log likelihood statistics. This is useful when INCLUDE_ALL_COLLOCS is True.</td>
  </tr><tr class="constant">
    
    <td>Constant</td>
    <td><code><a href="#SENT_STARTER" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer.SENT_STARTER">SENT​_STARTER</a></code></td>
    <td>minimal log-likelihood value that a token requires to be considered as a frequent sentence starter</td>
  </tr><tr class="staticmethod private">
    
    <td>Static Method</td>
    <td><code><a href="#_col_log_likelihood" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._col_log_likelihood">_col​_log​_likelihood</a></code></td>
    <td>A function that will just compute log-likelihood estimate, in the original paper it's described in algorithm 6 and 7.</td>
  </tr><tr class="staticmethod private">
    
    <td>Static Method</td>
    <td><code><a href="#_dunning_log_likelihood" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._dunning_log_likelihood">_dunning​_log​_likelihood</a></code></td>
    <td>A function that calculates the modified Dunning log-likelihood ratio scores for abbreviation candidates.  The details of how this works is available in the paper.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_find_collocations" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._find_collocations">_find​_collocations</a></code></td>
    <td>Generates likely collocations and their log-likelihood.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_find_sent_starters" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._find_sent_starters">_find​_sent​_starters</a></code></td>
    <td>Uses collocation heuristics for each candidate token to determine if it frequently starts sentences.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_freq_threshold" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._freq_threshold">_freq​_threshold</a></code></td>
    <td>Returns a FreqDist containing only data with counts below a given threshold, as well as a mapping (None -&gt; count_removed).</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_get_orthography_data" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._get_orthography_data">_get​_orthography​_data</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_get_sentbreak_count" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._get_sentbreak_count">_get​_sentbreak​_count</a></code></td>
    <td>Returns the number of sentence breaks marked in a given set of augmented tokens.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_potential_collocation" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._is_potential_collocation">_is​_potential​_collocation</a></code></td>
    <td>Returns True if the pair of tokens may form a collocation given log-likelihood statistics.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_potential_sent_starter" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._is_potential_sent_starter">_is​_potential​_sent​_starter</a></code></td>
    <td>Returns True given a token and the token that preceds it if it seems clear that the token is beginning a sentence.</td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_rare_abbrev_type" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._is_rare_abbrev_type">_is​_rare​_abbrev​_type</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_reclassify_abbrev_types" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._reclassify_abbrev_types">_reclassify​_abbrev​_types</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_train_tokens" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._train_tokens">_train​_tokens</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_unique_types" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._unique_types">_unique​_types</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_collocation_fdist" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._collocation_fdist">_collocation​_fdist</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_finalized" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._finalized">_finalized</a></code></td>
    <td>A flag as to whether the training has been finalized by finding collocations and sentence starters, or whether finalize_training() still needs to be called.</td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_num_period_toks" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._num_period_toks">_num​_period​_toks</a></code></td>
    <td>The number of words ending in period in the training data.</td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_sent_starter_fdist" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._sent_starter_fdist">_sent​_starter​_fdist</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_sentbreak_count" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._sentbreak_count">_sentbreak​_count</a></code></td>
    <td>The total number of sentence breaks identified in training, used for calculating the frequent sentence starter heuristic.</td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_type_fdist" class="internal-link" title="nltk.tokenize.punkt.PunktTrainer._type_fdist">_type​_fdist</a></code></td>
    <td>A frequency distribution giving the frequency of each case-normalized token type in the training data.</td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.punkt.PunktBaseClass.html" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a></code>:
          </p>
          <table class="children sortable" id="id1807">
  
  
  <tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_annotate_first_pass" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._annotate_first_pass">_annotate​_first​_pass</a></code></td>
    <td>Perform the first pass of annotation, which makes decisions based purely based on the word type of each word:</td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_first_pass_annotation" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._first_pass_annotation">_first​_pass​_annotation</a></code></td>
    <td>Performs type-based annotation on a single token.</td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_tokenize_words" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._tokenize_words">_tokenize​_words</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_lang_vars" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._lang_vars">_lang​_vars</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_params" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._params">_params</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_Token" class="internal-link" title="nltk.tokenize.punkt.PunktBaseClass._Token">_​Token</a></code></td>
    <td>The collection of parameters that determines the behavior of the punkt tokenizer.</td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, train_text=None, verbose=False, lang_vars=None, token_cls=<a href="nltk.tokenize.punkt.PunktToken.html" class="internal-link" title="nltk.tokenize.punkt.PunktToken">PunktToken</a>):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L632">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#__init__" class="internal-link">nltk.tokenize.punkt.PunktBaseClass.__init__</a></code></div>
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.finalize_training">
    
  </a>
  <a name="finalize_training">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">finalize_training</span>(self, verbose=False):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L811">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Uses data that has been gathered in training to determine likely
collocations and sentence starters.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.find_abbrev_types">
    
  </a>
  <a name="find_abbrev_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">find_abbrev_types</span>(self):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L996">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Recalculates abbreviations given type frequencies, despite no prior
determination of abbreviations.
This fails to include abbreviations otherwise found as "rare".</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.freq_threshold">
    
  </a>
  <a name="freq_threshold">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">freq_threshold</span>(self, ortho_thresh=2, type_thresh=2, colloc_thres=2, sentstart_thresh=2):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L834">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Allows memory use to be reduced after much training by removing data
about rare tokens that are unlikely to have a statistical effect with
further training. Entries occurring above the given thresholds will be
retained.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.get_params">
    
  </a>
  <a name="get_params">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">get_params</span>(self):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L673">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Calculates and returns parameters for sentence boundary detection as
derived from training.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.train">
    
  </a>
  <a name="train">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train</span>(self, text, verbose=False, finalize=True):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L726">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Collects training data from a given text. If finalize is True, it
will determine all the parameters for sentence boundary detection. If
not, this will be delayed until get_params() or finalize_training() is
called. If verbose is True, abbreviations found will be listed.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.train_tokens">
    
  </a>
  <a name="train_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train_tokens</span>(self, tokens, verbose=False, finalize=True):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L739">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Collects training data from a given list of tokens.</div>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.ABBREV">
    
  </a>
  <a name="ABBREV">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ABBREV</span>: <code>float</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L685">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>cut-off value whether a 'token' is an abbreviation</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>0.3</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.ABBREV_BACKOFF">
    
  </a>
  <a name="ABBREV_BACKOFF">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ABBREV_BACKOFF</span>: <code>int</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L693">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>upper cut-off for Mikheev's(2002) abbreviation detection algorithm</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>5</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.COLLOCATION">
    
  </a>
  <a name="COLLOCATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">COLLOCATION</span>: <code>float</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L696">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>minimal log-likelihood value that two tokens need to be considered
as a collocation</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>7.88</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.IGNORE_ABBREV_PENALTY">
    
  </a>
  <a name="IGNORE_ABBREV_PENALTY">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">IGNORE_ABBREV_PENALTY</span>: <code>bool</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L688">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>allows the disabling of the abbreviation penalty heuristic, which
exponentially disadvantages words that are found at times without a
final period.</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>False</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ABBREV_COLLOCS">
    
  </a>
  <a name="INCLUDE_ABBREV_COLLOCS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">INCLUDE_ABBREV_COLLOCS</span>: <code>bool</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L709">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>this includes as potential collocations all word pairs where the first
word is an abbreviation. Such collocations override the orthographic
heuristic, but not the sentence starter heuristic. This is overridden by
INCLUDE_ALL_COLLOCS, and if both are false, only collocations with initials
and ordinals are considered.</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>False</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ALL_COLLOCS">
    
  </a>
  <a name="INCLUDE_ALL_COLLOCS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">INCLUDE_ALL_COLLOCS</span>: <code>bool</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L704">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>this includes as potential collocations all word pairs where the first
word ends in a period. It may be useful in corpora where there is a lot
of variation that makes abbreviations like Mr difficult to identify.</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>False</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.MIN_COLLOC_FREQ">
    
  </a>
  <a name="MIN_COLLOC_FREQ">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">MIN_COLLOC_FREQ</span>: <code>int</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L717">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>this sets a minimum bound on the number of times a bigram needs to
appear before it can be considered a collocation, in addition to log
likelihood statistics. This is useful when INCLUDE_ALL_COLLOCS is True.</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>1</code></pre></td></tr></table>
  </div>
</div><div class="baseconstant">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer.SENT_STARTER">
    
  </a>
  <a name="SENT_STARTER">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">SENT_STARTER</span>: <code>int</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L700">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>minimal log-likelihood value that a token requires to be considered
as a frequent sentence starter</div>
    <table class="valueTable"><tr class="fieldStart"><td class="fieldName">Value</td></tr><tr><td><pre class="constant-value"><code>30</code></pre></td></tr></table>
  </div>
</div><div class="basestaticmethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._col_log_likelihood">
    
  </a>
  <a name="_col_log_likelihood">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_col_log_likelihood</span>(count_a, count_b, count_ab, N):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1076">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>A function that will just compute log-likelihood estimate, in
the original paper it's described in algorithm 6 and 7.</p>
<p>This <em>should</em> be the original Dunning log-likelihood values,
unlike the previous log_l function where it used modified
Dunning log-likelihood values</p>
</div>
  </div>
</div><div class="basestaticmethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._dunning_log_likelihood">
    
  </a>
  <a name="_dunning_log_likelihood">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_dunning_log_likelihood</span>(count_a, count_b, count_ab, N):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1059">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>A function that calculates the modified Dunning log-likelihood
ratio scores for abbreviation candidates.  The details of how
this works is available in the paper.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._find_collocations">
    
  </a>
  <a name="_find_collocations">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_find_collocations</span>(self):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1142">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Generates likely collocations and their log-likelihood.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._find_sent_starters">
    
  </a>
  <a name="_find_sent_starters">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_find_sent_starters</span>(self):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1191">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Uses collocation heuristics for each candidate token to
determine if it frequently starts sentences.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._freq_threshold">
    
  </a>
  <a name="_freq_threshold">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_freq_threshold</span>(self, fdist, threshold):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L859">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns a FreqDist containing only data with counts below a given
threshold, as well as a mapping (None -&gt; count_removed).</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._get_orthography_data">
    
  </a>
  <a name="_get_orthography_data">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_get_orthography_data</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L881">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Collect information about whether each token type occurs
with different case patterns (i) overall, (ii) at
sentence-initial positions, and (iii) at sentence-internal
positions.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._get_sentbreak_count">
    
  </a>
  <a name="_get_sentbreak_count">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_get_sentbreak_count</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1220">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the number of sentence breaks marked in a given set of
augmented tokens.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_potential_collocation">
    
  </a>
  <a name="_is_potential_collocation">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_potential_collocation</span>(self, aug_tok1, aug_tok2):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1127">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns True if the pair of tokens may form a collocation given
log-likelihood statistics.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_potential_sent_starter">
    
  </a>
  <a name="_is_potential_sent_starter">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_potential_sent_starter</span>(self, cur_tok, prev_tok):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1177">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns True given a token and the token that preceds it if it
seems clear that the token is beginning a sentence.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_rare_abbrev_type">
    
  </a>
  <a name="_is_rare_abbrev_type">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_rare_abbrev_type</span>(self, cur_tok, next_tok):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L1011">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><dl class="rst-docutils">
<dt>A word type is counted as a rare abbreviation if...</dt>
<dd><ul class="rst-first rst-last rst-simple">
<li>it's not already marked as an abbreviation</li>
<li>it occurs fewer than ABBREV_BACKOFF times</li>
<li>either it is followed by a sentence-internal punctuation
mark, <em>or</em> it is followed by a lower-case word that
sometimes appears with upper case, but never occurs with
lower case at the beginning of sentences.</li>
</ul>
</dd>
</dl>
</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._reclassify_abbrev_types">
    
  </a>
  <a name="_reclassify_abbrev_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_reclassify_abbrev_types</span>(self, types):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L929">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><dl class="rst-docutils">
<dt>(Re)classifies each given token if</dt>
<dd><ul class="rst-first rst-last rst-simple">
<li>it is period-final and not a known abbreviation; or</li>
<li>it is not period-final and is otherwise a known abbreviation</li>
</ul>
</dd>
</dl>
<p>by checking whether its previous classification still holds according
to the heuristics of section 3.
Yields triples (abbr, score, is_add) where abbr is the type in question,
score is its log-likelihood with penalties applied, and is_add specifies
whether the present type is a candidate for inclusion or exclusion as an
abbreviation, such that:</p>
<blockquote>
<ul class="rst-simple">
<li>(is_add and score &gt;= 0.3)    suggests a new abbreviation; and</li>
<li>(not is_add and score &lt; 0.3) suggests excluding an abbreviation.</li>
</ul>
</blockquote>
</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._train_tokens">
    
  </a>
  <a name="_train_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_train_tokens</span>(self, tokens, verbose):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L747">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._unique_types">
    
  </a>
  <a name="_unique_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_unique_types</span>(self, tokens):
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L808">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._collocation_fdist">
    
  </a>
  <a name="_collocation_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_collocation_fdist</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L645">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>A frequency distribution giving the frequency of all
bigrams in the training data where the first word ends in a
period.  Bigrams are encoded as tuples of word types.
Especially common collocations are extracted from this
frequency distribution, and stored in
<tt class="rst-docutils literal">_params</tt>.``collocations &lt;PunktParameters.collocations&gt;``.</div>
    
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._finalized">
    
  </a>
  <a name="_finalized">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_finalized</span>: <code>bool</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L665">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>A flag as to whether the training has been finalized by finding
collocations and sentence starters, or whether finalize_training()
still needs to be called.</div>
    
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._num_period_toks">
    
  </a>
  <a name="_num_period_toks">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_num_period_toks</span>: <code>int</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L642">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>The number of words ending in period in the training data.</div>
    
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._sent_starter_fdist">
    
  </a>
  <a name="_sent_starter_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_sent_starter_fdist</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L653">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>A frequency distribution giving the frequency of all words
that occur at the training data at the beginning of a sentence
(after the first pass of annotation).  Especially common
sentence starters are extracted from this frequency
distribution, and stored in <tt class="rst-docutils literal">_params.sent_starters</tt>.</div>
    
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._sentbreak_count">
    
  </a>
  <a name="_sentbreak_count">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_sentbreak_count</span>: <code>int</code> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L661">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>The total number of sentence breaks identified in training, used for
calculating the frequent sentence starter heuristic.</div>
    
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tokenize.punkt.PunktTrainer._type_fdist">
    
  </a>
  <a name="_type_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_type_fdist</span> =
    <a class="sourceLink" href="https://github.com/nltk/nltk/tree/3.6.2/nltk/tokenize/punkt.py#L638">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div>A frequency distribution giving the frequency of each
case-normalized token type in the training data.</div>
    
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.2.dev0 at 2022-03-04 17:22:04.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>