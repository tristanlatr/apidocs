<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.classify</title>
    <meta name="generator" content="pydoctor 22.2.2.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a> <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        <div>
          <span class="label label-default" id="search-docstrings-button">
            <a title="Search in docstrings" onclick="toggleSearchInDocstrings()">search in docstrings</a></span>
        </div>

        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all objects 
                  in "twisted.mail" that matches “search”: <code>+qname:twisted.mail.* +search</code>

                  <p>
                    Possible fields: 'name', 'qname' (fully qualified name), 'docstring', and 'kind'.
                    Last two fields are only applicable if "search in docstrings" is enabled.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>
        
        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div style="margin-top: 8px;">
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>
  </div>

  <script src="ajax.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="package"><code><code><a href="index.html" class="internal-link">nltk</a></code><wbr></wbr>.<code><a href="nltk.classify.html" class="internal-link" title="nltk.classify">classify</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        package documentation
      </div>

      <div class="extrasDocstring">
        <a href="https://github.com/nltk/nltk/tree/3.6.2/nltk/classify/__init__.py" class="sourceLink">(source)</a>
        <p></p>
      </div>

      <div class="moduleDocstring">
        <div><p>Classes and interfaces for labeling tokens with category labels (or
"class labels").  Typically, labels are represented with strings
(such as <tt class="rst-docutils literal">'health'</tt> or <tt class="rst-docutils literal">'sports'</tt>).  Classifiers can be used to
perform a wide range of classification tasks.  For example,
classifiers can be used...</p>
<ul class="rst-simple">
<li>to classify documents by topic</li>
<li>to classify ambiguous words by which word sense is intended</li>
<li>to classify acoustic signals by which phoneme they represent</li>
<li>to classify sentences by their author</li>
</ul>
<div class="rst-section" id="rst-features">
<h2 class="heading">Features</h2>
<p>In order to decide which category label is appropriate for a given
token, classifiers examine one or more 'features' of the token.  These
"features" are typically chosen by hand, and indicate which aspects
of the token are relevant to the classification decision.  For
example, a document classifier might use a separate feature for each
word, recording how often that word occurred in the document.</p>
</div>
<div class="rst-section" id="rst-featuresets">
<h2 class="heading">Featuresets</h2>
<p>The features describing a token are encoded using a "featureset",
which is a dictionary that maps from "feature names" to "feature
values".  Feature names are unique strings that indicate what aspect
of the token is encoded by the feature.  Examples include
<tt class="rst-docutils literal">'prevword'</tt>, for a feature whose value is the previous word; and
<tt class="rst-docutils literal"><span class="pre">'contains-word(library)'</span></tt> for a feature that is true when a document
contains the word <tt class="rst-docutils literal">'library'</tt>.  Feature values are typically
booleans, numbers, or strings, depending on which feature they
describe.</p>
<p>Featuresets are typically constructed using a "feature detector"
(also known as a "feature extractor").  A feature detector is a
function that takes a token (and sometimes information about its
context) as its input, and returns a featureset describing that token.
For example, the following feature detector converts a document
(stored as a list of words) to a featureset describing the set of
words included in the document:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-comment"># Define a feature detector function.</span>
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">def</span> <span class="py-defname">document_features</span>(document):
<span class="py-more">... </span>    <span class="py-keyword">return</span> <span class="py-builtin">dict</span>([(<span class="py-string">'contains-word(%s)'</span> % w, <span class="py-builtin">True</span>) <span class="py-keyword">for</span> w <span class="py-keyword">in</span> document])</pre></blockquote>
<p>Feature detectors are typically applied to each token before it is fed
to the classifier:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-comment"># Classify each Gutenberg document.</span>
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.corpus <span class="py-keyword">import</span> gutenberg
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">for</span> fileid <span class="py-keyword">in</span> gutenberg.fileids(): <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">... </span>    doc = gutenberg.words(fileid) <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">... </span>    <span class="py-builtin">print</span>(fileid, classifier.classify(document_features(doc))) <span class="py-comment"># doctest: +SKIP</span></pre></blockquote>
<p>The parameters that a feature detector expects will vary, depending on
the task and the needs of the feature detector.  For example, a
feature detector for word sense disambiguation (WSD) might take as its
input a sentence, and the index of a word that should be classified,
and return a featureset for that word.  The following feature detector
for WSD includes features describing the left and right contexts of
the target word:</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">def</span> <span class="py-defname">wsd_features</span>(sentence, index):
<span class="py-more">... </span>    featureset = {}
<span class="py-more">... </span>    <span class="py-keyword">for</span> i <span class="py-keyword">in</span> <span class="py-builtin">range</span>(<span class="py-builtin">max</span>(0, index-3), index):
<span class="py-more">... </span>        featureset[<span class="py-string">'left-context(%s)'</span> % sentence[i]] = <span class="py-builtin">True</span>
<span class="py-more">... </span>    <span class="py-keyword">for</span> i <span class="py-keyword">in</span> <span class="py-builtin">range</span>(index, <span class="py-builtin">max</span>(index+3, <span class="py-builtin">len</span>(sentence))):
<span class="py-more">... </span>        featureset[<span class="py-string">'right-context(%s)'</span> % sentence[i]] = <span class="py-builtin">True</span>
<span class="py-more">... </span>    <span class="py-keyword">return</span> featureset</pre></blockquote>
</div>
<div class="rst-section" id="rst-training-classifiers">
<h2 class="heading">Training Classifiers</h2>
<p>Most classifiers are built by training them on a list of hand-labeled
examples, known as the "training set".  Training sets are represented
as lists of <tt class="rst-docutils literal">(featuredict, label)</tt> tuples.</p>
</div>
</div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id133">
  
  
  <tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.api.html" class="internal-link" title="nltk.classify.api">api</a></code></td>
    <td>Interfaces for labeling tokens with category labels (or "class labels").</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.decisiontree.html" class="internal-link" title="nltk.classify.decisiontree">decisiontree</a></code></td>
    <td>A classifier model that decides which label to assign to a token on the basis of a tree structure, where branches correspond to conditions on feature values, and leaves correspond to label assignments.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.maxent.html" class="internal-link" title="nltk.classify.maxent">maxent</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.megam.html" class="internal-link" title="nltk.classify.megam">megam</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.naivebayes.html" class="internal-link" title="nltk.classify.naivebayes">naivebayes</a></code></td>
    <td>A classifier based on the Naive Bayes algorithm.  In order to find the probability for a label, this algorithm first uses the Bayes rule to express P(label|features) in terms of P(label) and P(features|label):</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.positivenaivebayes.html" class="internal-link" title="nltk.classify.positivenaivebayes">positivenaivebayes</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.rte_classify.html" class="internal-link" title="nltk.classify.rte_classify">rte​_classify</a></code></td>
    <td>Simple classifier for RTE corpus.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.scikitlearn.html" class="internal-link" title="nltk.classify.scikitlearn">scikitlearn</a></code></td>
    <td>scikit-learn (<a class="rst-reference external" href="http://scikit-learn.org" target="_top">http://scikit-learn.org</a>) is a machine learning library for Python. It supports many classification algorithms, including SVMs, Naive Bayes, logistic regression (MaxEnt) and decision trees.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.senna.html" class="internal-link" title="nltk.classify.senna">senna</a></code></td>
    <td>A general interface to the SENNA pipeline that supports any of the operations specified in SUPPORTED_OPERATIONS.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.svm.html" class="internal-link" title="nltk.classify.svm">svm</a></code></td>
    <td>nltk.classify.svm was deprecated. For classification based on support vector machines SVMs use nltk.classify.scikitlearn (or <a class="rst-reference external" href="http://scikit-learn.org" target="_top">scikit-learn</a> directly).</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.tadm.html" class="internal-link" title="nltk.classify.tadm">tadm</a></code></td>
    <td><span class="undocumented">No module docstring; 0/1 variable, 3/6 functions documented</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.textcat.html" class="internal-link" title="nltk.classify.textcat">textcat</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.util.html" class="internal-link" title="nltk.classify.util">util</a></code></td>
    <td>Utility functions and classes for classifiers.</td>
  </tr><tr class="module">
    
    <td>Module</td>
    <td><code><a href="nltk.classify.weka.html" class="internal-link" title="nltk.classify.weka">weka</a></code></td>
    <td>Classifiers that make use of the external 'Weka' package.</td>
  </tr>
</table>
        

          
      </div>

      <div id="childList">

        

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="http://www.nltk.org/" class="projecthome">nltk-3.6.2</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.2.dev0 at 2022-03-04 17:22:04.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>